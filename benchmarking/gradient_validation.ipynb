{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23996f92-0536-4268-8598-fffef49740ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06a73318-3f3d-4d5b-9fcf-b73b015544c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53cbbe32-8c55-4209-9f39-a09360ea064a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from micrograd.engine import Value\n",
    "from micrograd.nn import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a43a4-4005-4ed7-96e8-d837c8844a0c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dbfeeee-dcf1-47a3-8ba7-fd52b8c9b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=100, noise=0.1)\n",
    "y = y * 2 - 1  # make y be -1 or 1\n",
    "\n",
    "# --- PyTorch Version ---\n",
    "X_torch = torch.tensor(X, dtype=torch.float32)\n",
    "y_torch = torch.tensor(y, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc80af7-93fa-497b-8602-45033b98e6e4",
   "metadata": {},
   "source": [
    "# Pytorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dae8e83-7fd1-475b-8adc-c698c7dd5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "model_torch = TorchMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1759972-fee1-4858-a219-6c1beb5859fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model_torch(X_torch)\n",
    "losses = torch.relu(1 + -y_torch * scores)\n",
    "data_loss = losses.mean()\n",
    "reg_loss = 1e-4 * sum((p ** 2).sum() for p in model_torch.parameters())\n",
    "loss_t = data_loss + reg_loss\n",
    "loss_t.backward()\n",
    "\n",
    "torch_grads = model_torch.fc1.weight.grad.detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee1408d-ed9c-4556-bf89-4cc16ad84c7d",
   "metadata": {},
   "source": [
    "# Micrograd Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18003cd9-c53c-4b6e-ae85-4e9d762d9bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_micro = MLP(2, [16, 16, 1])\n",
    "\n",
    "def micro_loss(X, y):\n",
    "    inputs = [list(map(Value, xrow)) for xrow in X]\n",
    "    scores = list(map(model_micro, inputs))\n",
    "    losses = [(1 + -yi * score).relu() for yi, score in zip(y, scores)]\n",
    "    data_loss = sum(losses) * (1.0 / len(losses))\n",
    "    reg_loss = 1e-4 * sum((p * p for p in model_micro.parameters()))\n",
    "    total_loss = data_loss + reg_loss\n",
    "    return total_loss\n",
    "\n",
    "total_loss = micro_loss(X, y)\n",
    "model_micro.zero_grad()\n",
    "total_loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8937ade5-a7c4-4b55-bafb-9c468896fb5f",
   "metadata": {},
   "source": [
    "extracting gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4084bfa1-a9ed-4cd7-a7f2-a9df213b218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "W0_grads = np.array([[p.grad for p in neuron.w] for neuron in model_micro.layers[0].neurons])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec83b01-0fb1-4939-a985-5c29610c82c3",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "303c95fc-806c-430c-b7e1-8a33df62b6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max absolute error: 0.34151939979542156\n",
      "Mean absolute error: 0.09357949932870627\n"
     ]
    }
   ],
   "source": [
    "abs_diff = np.abs(torch_grads - W0_grads)\n",
    "max_abs_error = abs_diff.max()\n",
    "mean_abs_error = abs_diff.mean()\n",
    "\n",
    "print(\"Max absolute error:\", max_abs_error)\n",
    "print(\"Mean absolute error:\", mean_abs_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea03b5b4-c6c3-4ebd-bb11-4bbb65a0518c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
